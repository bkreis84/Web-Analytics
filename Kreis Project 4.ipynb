{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 \n",
    "\n",
    "#### In this assignment we evaluate the results of the movie review classifier found in chapter 6. Because the accuracy was found to only be 65% I also looked at bigrams which increased the accuracy to nearly 77%\n",
    "\n",
    "\n",
    "### References:\n",
    "[NLTK](http://www.nltk.org/book/ch06.html) Chapter 6   \n",
    "[Streamhacker](http://streamhacker.com/2010/05/24/text-classification-sentiment-analysis-stopwords-collocations/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(words)[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features(document): \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streamhacker has some useful information on using other nltk packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    " \n",
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=1500):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(bigram_word_feats(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     18.6 : 1.0\n",
      "             magnificent = True              pos : neg    =     13.5 : 1.0\n",
      "     (u'matt', u'damon') = True              pos : neg    =     12.1 : 1.0\n",
      "               fictional = True              pos : neg    =     11.5 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.2 : 1.0\n",
      "         (u's', u'just') = True              neg : pos    =     10.5 : 1.0\n",
      "              schumacher = True              neg : pos    =     10.5 : 1.0\n",
      "                depicted = True              pos : neg    =     10.2 : 1.0\n",
      "                   damon = True              pos : neg    =     10.0 : 1.0\n",
      "                  seagal = True              neg : pos    =      9.8 : 1.0\n",
      "                  finger = True              neg : pos    =      9.8 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.6 : 1.0\n",
      "                  avoids = True              pos : neg    =      9.5 : 1.0\n",
      "     (u'well', u'worth') = True              pos : neg    =      9.5 : 1.0\n",
      "       (u'was', u'made') = True              neg : pos    =      9.1 : 1.0\n",
      "               stupidity = True              neg : pos    =      9.1 : 1.0\n",
      "      (u'your', u'time') = True              neg : pos    =      9.1 : 1.0\n",
      "       (u'be', u'funny') = True              neg : pos    =      9.1 : 1.0\n",
      "                    cope = True              pos : neg    =      8.9 : 1.0\n",
      "                 tribute = True              pos : neg    =      8.9 : 1.0\n",
      "                      na = True              pos : neg    =      8.9 : 1.0\n",
      "               strongest = True              pos : neg    =      8.9 : 1.0\n",
      "              revolution = True              pos : neg    =      8.9 : 1.0\n",
      "                  forgot = True              neg : pos    =      8.7 : 1.0\n",
      "             outstanding = True              pos : neg    =      8.5 : 1.0\n",
      "                    sans = True              neg : pos    =      8.5 : 1.0\n",
      "  (u'quite', u'frankly') = True              neg : pos    =      8.5 : 1.0\n",
      "              incoherent = True              neg : pos    =      8.5 : 1.0\n",
      "      (u'work', u'with') = True              neg : pos    =      8.5 : 1.0\n",
      "       (u'wouldn', u\"'\") = True              neg : pos    =      8.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these make sense, even the comical fact that Matt Damon is a positive indicator and Steven Seagal and Schumacher are negative indicators. I tried to think of anything positive that could be said before or after \"be funny\" and could not think of anything (tries to be funny is probably most common). \"quite frankly\" is something which is generally said within a negative statement. \n",
    "\n",
    "Some that were rather surprising:\n",
    "\"work with\", \"was made\", \"finger\", \"fictional\" at first glance would seem to have neither a negative or positive connotation, which aside from \"fictional\", all ended up being negative indicators. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
